[
  
  {
    "title": "Prototypical Networks",
    "url": "/posts/protonet/",
    "categories": "Meta-learning",
    "tags": "",
    "date": "2022-12-30 09:37:21 +0100",
    





    "snippet": "Prototypical networks are a type of few-shot learning model that was first introduced by Snell et al. 2017. They are designed to learn to classify new examples by comparing them to a small number of examples from each class, or “prototypes.” The idea behind prototypical networks is that each class can be represented by a prototype, which is a representative example of that class.Prototypical networks are typically implemented as neural networks and are trained using a combination of supervised learning and unsupervised learning. In the supervised learning phase, the model is trained on a large dataset with labeled examples and learns to classify examples based on their features. In the unsupervised learning phase, the model is presented with a small number of examples from each class and learns to identify the prototypes for each class based on the features of the examples.To classify a new example, the model compares the features of the example to the prototypes for each class and predicts the class of the prototype that is most similar to the example. This allows the model to classify new examples using only a small number of labeled examples from each class, making it well-suited for few-shot learning tasks.Prototypical networks have been shown to be effective in a variety of NLP tasks, including text classification and entity recognition. They have the advantage of being able to learn from a small number of labeled examples, making them a useful tool for few-shot learning scenarios where annotated data is limited.Reference:Snell, J., Swersky, K., &amp; Zemel, R. (2017). Prototypical Networks For Few-Shot Learning"
  },
  
  {
    "title": "Event Extraction",
    "url": "/posts/event-extraction/",
    "categories": "IE",
    "tags": "",
    "date": "2022-12-12 19:01:21 +0100",
    





    "snippet": "Event extraction is the task of identifying events in a text and extracting information about the participants, time, location, and other details of the event. It is an important subtask of natural language processing (NLP) and is used in various applications such as question answering, text summarization, and knowledge base construction.There are several sub-tasks involved in event extraction, including event classification, event argument extraction, and event trigger identification. Event classification involves identifying the type of event mentioned in the text (e.g., “person X was arrested”), while event argument extraction involves identifying the participants, time, location, and other details of the event (e.g., “person X was arrested by the police at 5pm on Main Street”). Event trigger identification involves identifying the words or phrases that signal the occurrence of an event (e.g., “arrested”).There are several approaches to event extraction, including rule-based, machine learning-based, and deep learning-based methods. Rule-based methods rely on manually defined rules to extract events, while machine learning-based methods use supervised learning algorithms to learn from annotated data. Deep learning-based methods, on the other hand, use neural networks to learn from large amounts of unstructured data.One of the main challenges in event extraction is the need for large amounts of annotated data, which is text that has been manually labeled with the events it contains and the relevant details of those events. Annotating data is a time-consuming and costly process, and it is often difficult to obtain enough annotated data to train a high-quality event extraction model. To address this problem, researchers have developed methods for performing event extraction using weak supervision, which involves using partially annotated or noisy data to train the model.Event extraction has a wide range of applications, including question answering, text summarization, and knowledge base construction. In question answering, event extraction can be used to extract information about events mentioned in a question and use it to find the answer. In text summarization, event extraction can be used to extract the main events and details from a text and summarize them in a concise manner. In knowledge base construction, event extraction can be used to extract events and their details from texts and add them to a knowledge base."
  },
  
  {
    "title": "Relation Extraction (RE)",
    "url": "/posts/relation-extraction/",
    "categories": "IE",
    "tags": "",
    "date": "2022-10-03 17:15:21 +0200",
    





    "snippet": "Relation extraction is a natural language processing (NLP) task that involves identifying relationships between entities in a text. These relationships can be binary (e.g., “person X is the father of person Y”) or multi-valued (e.g., “person X works at company Y and company Z”).Relation extraction is a crucial component of information extraction systems, which aim to extract structured data from unstructured texts. It is also used in various applications such as question answering, summarization, and knowledge base construction.There are several approaches to relation extraction, including rule-based, machine learning-based, and deep learning-based methods. Rule-based methods rely on manually defined rules to extract relationships, while machine learning-based methods use supervised learning algorithms to learn from annotated data. Deep learning-based methods, on the other hand, use neural networks to learn from large amounts of unstructured data.One of the main challenges in relation extraction is the need for large amounts of annotated data, which is text that has been manually labeled with the relationships it contains. Annotating data is a time-consuming and costly process, and it is often difficult to obtain enough annotated data to train a high-quality relation extraction model. To address this problem, researchers have developed methods for performing relation extraction using weak supervision, which involves using partially annotated or noisy data to train the model.Overall, relation extraction is an important task in NLP that plays a key role in extracting structured data from unstructured texts. With the increasing availability of large datasets and the development of powerful machine learning and deep learning techniques, relation extraction is becoming more accurate and efficient."
  },
  
  {
    "title": "Named Entity Recognition (NER)",
    "url": "/posts/named-entity-recognition/",
    "categories": "IE",
    "tags": "",
    "date": "2022-09-30 16:15:21 +0200",
    





    "snippet": "In natural language processing, Named Entity Recognition (NER) is a common sub-tasks of Information Extraction that consists of identifying and classifing named entities in untructured texts, into predefined categories such as persons, locations, organizations, medical codes, time expressions, quantities, monetary values, etc. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category. For example, in the sentence “Google develloped a new AI model”, an NER model might detect the word “Google” in a text and classify it as a “Company”. It is an important subtask of natural language processing (NLP) and is used in various applications such as information extraction, question answering, and text summarization.One of the main challenges in NER is the need for large amounts of annotated data, which is text that has been manually labeled with the named entities it contains. Annotating data is a time-consuming and costly process, and it is often difficult to obtain enough annotated data to train a high-quality NER model.To address this problem, researchers have developed methods for performing NER in a few-shot manner, which means that the model can learn to recognize named entities using only a small amount of annotated data. These methods typically involve transfer learning, where a model pre-trained on a large dataset is fine-tuned on the smaller annotated dataset, or using unsupervised or semi-supervised learning techniques to learn from a larger amount of unlabeled data."
  },
  
  {
    "title": "Information Extraction (IE)",
    "url": "/posts/information-extraction/",
    "categories": "IE",
    "tags": "",
    "date": "2022-09-30 14:15:21 +0200",
    





    "snippet": "Information extraction is the process of extracting structured data from unstructured texts. It is an important task in natural language processing (NLP) and is used in various applications such as question answering, text summarization, and knowledge base construction.There are several sub-tasks involved in information extraction, including named entity recognition (NER), relation extraction, and event extraction. NER involves identifying and classifying named entities in a text, such as person names, organizations, and locations. Relation extraction involves identifying relationships between entities in a text, such as “person X works at company Y.” Event extraction involves identifying events in a text and extracting information about the participants, time, location, and other details of the event.One of the main challenges in information extraction is the need for large amounts of annotated data, which is text that has been manually labeled with the structured data it contains. Annotating data is a time-consuming and costly process, and it is often difficult to obtain enough annotated data to train a high-quality information extraction model.To address this problem, researchers have developed methods for performing information extraction in a few-shot manner, which means that the model can learn to extract structured data using only a small amount of annotated data. These methods typically involve transfer learning, where a model pre-trained on a large dataset is fine-tuned on the smaller annotated dataset, or using unsupervised or semi-supervised learning techniques to learn from a larger amount of unlabeled data.Overall, information extraction is an important task in NLP that plays a key role in extracting structured data from unstructured texts. With the increasing availability of large datasets and the development of powerful machine learning and deep learning techniques, information extraction is becoming more accurate and efficient. However, the challenge of performing information extraction with limited annotated data remains an active area of research.This is the context of my current research with a focus on Event Extraction. I am especially interested in transfer methods using pre-trained language models combined with meta-learning.Transfer methods involve using a model pre-trained on a large dataset and fine-tuning it for a specific task. Pre-trained language models, such as BERT (Bidirectional Encoder Representations from Transformers), are trained on large datasets and can be fine-tuned for a variety of NLP tasks. Meta-learning involves training a model on a set of tasks and then using this knowledge to learn new tasks quickly.I am working on developing a model that can perform event extraction with a small amount of annotated data. This involves using a pre-trained language model as the base model and fine-tuning it on a small annotated dataset for event extraction, and then using meta-learning techniques to learn from this small dataset and adapt quickly to new tasks.This is a challenging problem in the field of natural language processing, and I am excited to be working on it."
  }
  
]

